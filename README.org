#+TITLE: Code assignment
#+PROPERTY: header-args :eval never-export :results code :noweb no :tangle no :exports both
#+PROPERTY: header-args:shell :shebang #!/usr/bin/env -S bash -euo pipefail 
#+OPTIONS: toc:3
#+OPTIONS: broken-links:mark
#+EXPORT_EXCLUDE_TAGS: noexport
#+STARTUP: overview

* Table of contents :toc:
- [[#code-refactor-moviedetailgetterpy][Code Refactor (MovieDetailGetter.py)]]
  - [[#manifest][Manifest]]
  - [[#summary][Summary]]
  - [[#build-image][Build image]]
  - [[#running][Running]]
  - [[#deleting-the-image][Deleting the image]]
- [[#alignment-mapping-cigar-string][Alignment Mapping (CIGAR string)]]
  - [[#manifest-1][Manifest]]
  - [[#summary-strengths-and-weaknesses][Summary (Strengths and Weaknesses)]]
  - [[#build-image-1][Build image]]
  - [[#running-1][Running]]
  - [[#deleting-the-image-1][Deleting the image]]

* Code Refactor (MovieDetailGetter.py)

** Manifest
*** [[file:./test_1/Makefile][Makefile]]
  A Makefile is used to automate tasks such as creating, testing, and deleting the Docker image for the project host.
*** [[file:./test_1/Dockerfile][Dockerfile]]
  A Dockerfile script is used to build the project's Docker image.
*** [[file:./test_1/setup.py][setup.py]]
  The setup.py file packages the Python project. In this case, it checks if the necessary dependencies are installed and exports the MovieDetailGetter.py script to the virtual environment's bin folder. The Dockerfile appends this bin folder to the PATH variable of the running user, making the script and its dependencies available at runtime within the container.
*** [[file:./test_1/requirements.txt][requirements.txt]]
  A text file listing the dependencies required by the Python project.
*** [[file:./test_1/MovieDetailgetter.py][MovieDetailgetter.py]]
  This is the **MAIN** file of the project, containing the refactored code from the original script.
*** [[file:./test_1/input.csv][input.csv]]
  This file contains the original test data provided for the project. It is kept for verifying that the script works correctly.
  
** Summary

*** Code Organization and Modularity
The original script was procedural and lacked structure, with large blocks of code handling multiple tasks. During the refactor, I introduced clear modularity by splitting the code into distinct functions, such as get_top250_movies, database_handler, and query_database. I also incorporated decorators like @formatter and @subcommand, which streamline functionality and make future enhancements (such as adding new formatters or subcommands) simple and low-risk. This modular approach ensures that new features can be added without the risk of breaking existing functionality.

*** Clarity and Readability
The original code suffered from poor readability, including inconsistent naming, unused imports, and numerous commented-out sections. To improve clarity, I cleaned up imports, removed unnecessary comments, and renamed functions to more descriptive terms, such as replacing Printratingofmoviefromfile with extract_info_from_movie_as_dict. I also documented every function with proper docstrings to enhance maintainability. For additional clarity and to ensure consistent coding standards, I implemented type checking, used pylint for linting, and formatted the code with black.

*** Error Handling and Robustness
The original script lacked proper error handling, with some exceptions being caught but ignored. I introduced more robust error management by creating a custom exception, NoMatchFoundError, and used assertions to halt execution when necessary (e.g., when the database is empty). This not only improves error reporting but also ensures that the script does not fail silently. The added type checking further enhances the robustness by catching potential issues early in the development process.

*** Extensibility and Deployment
To improve the scriptâ€™s extensibility, I made modifications to the setup.py file to ensure the script is installable as a package. Additionally, I created a Docker image, making deployment simpler across different environments. These improvements not only enhance the modularity of the code but also make it more accessible for future growth and easier to run in any setup.

** Build image 
Run docker with make to create the run time image.
#+BEGIN_SRC shell :results code :exports both 
  make -C ./test_1 build
#+END_SRC

#+RESULTS:
#+begin_src shell
make: Entering directory '/home/hugo/projects/job_test/repo/test_1'
docker build -t "dev-movie-detail-getter" . && docker run --rm -i "dev-movie-detail-getter"
[1/2] STEP 1/9: FROM python:3.12-alpine AS base_image
[1/2] STEP 2/9: ARG VENV="/opt/venv"
--> Using cache f4393dc8c9564f3c1a13471cc04c4eb6c4099e278f23a0e6eac7a9cf987941ad
--> f4393dc8c956
[1/2] STEP 3/9: WORKDIR /tmp/build
--> Using cache d9e9f18adb51d120dd1475256fc9c620441322bbc8a5f122fbd498d799f42fa0
--> d9e9f18adb51
[1/2] STEP 4/9: RUN :     && apk update     && apk add --no-cache git     && :
--> Using cache ece00f9aad101ca98f34014a565254862f040e16057fb730abb000e86415f657
--> ece00f9aad10
[1/2] STEP 5/9: COPY requirements.txt requirements.txt
--> Using cache 730c00be60080beae998b8e860061b9a2b8410f2a8e3fcf8171f474881a0b06b
--> 730c00be6008
[1/2] STEP 6/9: RUN :     && /usr/bin/env python3 -m venv "${VENV}"     && "${VENV}/bin/python3" -m pip install --upgrade --no-cache-dir pip     && "${VENV}/bin/python3" -m pip install --no-cache-dir -r requirements.txt     && :
--> Using cache 72b1e3b3fd8224331f2daccca4c8e1b35a6e4dfad426dff462fc92759d78ea21
--> 72b1e3b3fd82
[1/2] STEP 7/9: COPY setup.py setup.py
--> Using cache 2abdc6ace9097a2ee3a5cd8133a9138a49480a0f0c84332e7b29adcfce3cae22
--> 2abdc6ace909
[1/2] STEP 8/9: COPY MovieDetailgetter.py MovieDetailgetter.py
--> Using cache 27fad416f2649dec20b372607ff130c9b853db21c65da25a3dff3de1beb33d14
--> 27fad416f264
[1/2] STEP 9/9: RUN :     && "${VENV}/bin/python3" setup.py install     && :
--> Using cache c03bcfe70311ad2d5ea5378e051a2c69373cb9333c6b5df24b76adef740fced8
--> c03bcfe70311
[2/2] STEP 1/6: FROM python:3.12-alpine AS runner
[2/2] STEP 2/6: ARG VENV="/opt/venv"
--> Using cache f4393dc8c9564f3c1a13471cc04c4eb6c4099e278f23a0e6eac7a9cf987941ad
--> f4393dc8c956
[2/2] STEP 3/6: COPY --from=base_image "${VENV}" "${VENV}"
--> Using cache c15b025214956c9957326448d1b2bbe6ef509d860038a26f164eeb1f35249978
--> c15b02521495
[2/2] STEP 4/6: ENV PATH="${VENV}/bin:${PATH}"
--> Using cache 8b72f555da03d5bdbd3384939f2d90858b82914483d569d20df9c9560c373f1c
--> 8b72f555da03
[2/2] STEP 5/6: ENTRYPOINT [ "MovieDetailgetter.py" ]
--> Using cache 9ee048bd1df9607a81e10be8cdfc5dd2490ee1c3419ee3e318d6818cd8f0d8b0
--> 9ee048bd1df9
[2/2] STEP 6/6: CMD [ "--help" ]
--> Using cache 552fde5c8097e30dd02a4c33eb81323e25ba50bb270c74f2dd88472e042b205b
[2/2] COMMIT dev-movie-detail-getter
--> 552fde5c8097
Successfully tagged localhost/dev-movie-detail-getter:latest
552fde5c8097e30dd02a4c33eb81323e25ba50bb270c74f2dd88472e042b205b
MovieDetailgetter.py

Usage:
    MovieDetailgetter.py db <DB_NAME> ( --dump | --create )
    MovieDetailgetter.py query <DB_NAME> --movie_title=<MOVIE_TITLE> [--get_field=<FIELD_NAME>] [--formatter=<FORMATTER>]

Options:
    -h, --help                       Show this screen.
    -d, --dump                       Print the database content.
    -c, --create                     Create a new database.
    -m, --movie_title=<MOVIE_TITLE>   Search for a specific movie by its title.
    -g, --get_field=<FIELD_NAME>      Specify the field to retrieve [default: rating].
    -f, --formatter=<FORMATTER>       Specify an output formatter for the query [default: default].

Description:
  MovieDetailgetter.py allows interaction with an IMDb database (Top 250 movies). 
  The 'db' command supports dumping or creating a database.
  The 'query' command searches for a specific movie by its title, with optional customizations 
  to retrieve specific fields and format the output.

  Formatters:
  - "default":
    Prints a formatted string with the specified field and value:

    $ MovieDetailgetter.py query imdb_top_250_movies.csv --movie_title 'The Shawshank Redemption'
    The Shawshank Redemption: rating is 9.3

  - "funny":
    Renders the movie rating using the cowsay library:

    $ MovieDetailgetter.py query imdb_top_250_movies.csv --movie_title 'The Shawshank Redemption' --get_field year --formatter funny
    <cowsay string>
make: Leaving directory '/home/hugo/projects/job_test/repo/test_1'
#+end_src

** Running
#+BEGIN_SRC shell :results code :exports both
  cd ./test_1

  # Remove the read_only (:ro) arg to create the db.
  dev-movie-detail-getter() {
      docker run --rm -i -v "${PWD}:${PWD}:ro" -w "${PWD}" dev-movie-detail-getter "${@}"
  }

  echo "[DB DUMP]"
  dev-movie-detail-getter db ./input.csv --dump
  echo

  echo "[QUERY]"
  dev-movie-detail-getter query ./input.csv --movie_title "Planet Earth II"
  echo 
  
  echo "[QUERY - GET YEAR - FUNNY FORMATTER]"
  dev-movie-detail-getter query ./input.csv --movie_title "Planet Earth II" --get_field year --formatter funny
  echo 
#+END_SRC

#+RESULTS:
#+begin_src shell
[DB DUMP]
place,movie_title,rating,year,star_cast
1,Planet Earth II,9.442943242909964,2016,"David Attenborough, Chadden Hunter"
2,Breaking Bad,9.42441683160262,2008,"Bryan Cranston, Aaron Paul"

[QUERY]
Planet Earth II: rating is 9.442943242909964!

[QUERY - GET YEAR - FUNNY FORMATTER]
 ________________________________ 
< Planet Earth II: year is 2016! >
 -------------------------------- 
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

#+end_src

** Deleting the image
Run this command to delete the app image.
#+BEGIN_SRC shell :results code :exports both
  make -C ./test_1/ clean
#+END_SRC

#+RESULTS:
#+begin_src shell
make: Entering directory '/home/hugo/projects/job_test/repo/test_1'
docker image rm "dev-movie-detail-getter"
Untagged: localhost/dev-movie-detail-getter:latest
Deleted: 552fde5c8097e30dd02a4c33eb81323e25ba50bb270c74f2dd88472e042b205b
Deleted: 9ee048bd1df9607a81e10be8cdfc5dd2490ee1c3419ee3e318d6818cd8f0d8b0
Deleted: 8b72f555da03d5bdbd3384939f2d90858b82914483d569d20df9c9560c373f1c
Deleted: c15b025214956c9957326448d1b2bbe6ef509d860038a26f164eeb1f35249978
make: Leaving directory '/home/hugo/projects/job_test/repo/test_1'
#+end_src

* Alignment Mapping (CIGAR string)

** Manifest
*** [[file:./test_2/Makefile][Makefile]]
  A Makefile is used to automate tasks such as creating, testing, and deleting the Docker image for the project host.
*** [[file:./test_2/Dockerfile][Dockerfile]]
  A Dockerfile script is used to build the project's Docker image.
*** [[file:./test_2/setup.py][setup.py]]
  The setup.py file packages the Python project. In this case, it checks if the necessary dependencies are installed and exports the part2_solver.py script to the virtual environment's bin folder. The Dockerfile appends this bin folder to the PATH variable of the running user, making the script and its dependencies available at runtime within the container.
*** [[file:./test_2/requirements.txt][requirements.txt]]
  A text file listing the dependencies required by the Python project.
*** [[file:./test_2/part2_solver.py][part2_solver.py]]
  This is the **MAIN** file of the project, it contains my solution for the CIGAR string test.
*** [[file:./test_2/input_1.tsv][input_1.tsv]]
  This is a text file with the test input choords.
*** [[file:./test_2/input_2.tsv][input_2.tsv]]
  This is a text file with the test input queries.
*** [[file:./test_2/expected_output.tsv][expected_output.tsv]]
  This is a text file the expected output.
  
** Summary (Strengths and Weaknesses)

*** Strengths
**** Modular and Composable Design
The code follows functional programming principles, making it **highly composable** and **modular**. Functions are dedicated to specific tasks like parsing CIGAR strings and generating alignments, improving maintainability and extensibility.
**** Optimized for Readability and Quality
The script is formatted using black and checked with pylint, ensuring a consistent coding style and readability. These tools also help enforce best practices and minimize potential errors.
**** Pythonic Code
 The code leverages Python's built-in functional features such as dataclasses, lru_cache, and list comprehensions. By focusing on writing expressive, Pythonic code, the script adheres to best practices, making it more concise, maintainable, and efficient.
**** Performance Improvements
 The use of lru_cache significantly enhances performance by avoiding redundant calculations, particularly during repeated tasks, ensuring the code scales well even for larger inputs.
**** Documentation and Naming
 Clear function names and detailed docstrings make the code understandable for other developers. This attention to documentation improves long-term maintainability.
*** Weaknesses

**** CIGAR Parsing Efficiency
 The current approach uses eager evaluation (re.findall), which might not scale well with larger datasets. Transitioning to a lazy evaluation strategy could improve efficiency and reduce memory consumption for bigger data sets.
**** Mapping Generation Efficiency
 The function that generates the mappings (alignments) also suffers from an eager evaluation approach. It currently creates all possible alignment tuples in advance, even if only a subset of those are needed. A better approach would be to implement a lazy evaluation method where alignment objects (such as Expr or tuples) are generated only when required. This would enhance performance and avoid unnecessary computations for larger data inputs.
**** Limited Error Scenarios
 While the script handles some basic error cases, it would benefit from more comprehensive testing and error handling. Particularly, additional checks for malformed CIGAR strings or incomplete input data could make the script more robust and fault-tolerant.

** Build image
Run docker with make to create the run time image.
#+BEGIN_SRC shell :results code :exports both 
  make -C ./test_2 build
#+END_SRC

#+RESULTS:
#+begin_src shell
make: Entering directory '/home/hugo/projects/job_test/repo/test_2'
docker build -t part-2-solver . && docker run --rm -i part-2-solver
[1/2] STEP 1/8: FROM python:3.12-alpine AS base_image
[1/2] STEP 2/8: ARG VENV="/opt/venv"
--> Using cache f4393dc8c9564f3c1a13471cc04c4eb6c4099e278f23a0e6eac7a9cf987941ad
--> f4393dc8c956
[1/2] STEP 3/8: WORKDIR /tmp/build
--> Using cache d9e9f18adb51d120dd1475256fc9c620441322bbc8a5f122fbd498d799f42fa0
--> d9e9f18adb51
[1/2] STEP 4/8: COPY requirements.txt requirements.txt
--> Using cache 9de1ddc6489fbdb7a18dacb5c5ff4fab8b619621cd8dbfc20cb1d1e2ff0d975c
--> 9de1ddc6489f
[1/2] STEP 5/8: RUN :     && /usr/bin/env python3 -m venv "${VENV}"     && "${VENV}/bin/python3" -m pip install --upgrade --no-cache-dir pip     && "${VENV}/bin/python3" -m pip install --no-cache-dir -r requirements.txt     && :
--> Using cache dc6ad65dd1818bc29d1aaabfc79f790cb60adcc2d91261dbb674242619b61d2a
--> dc6ad65dd181
[1/2] STEP 6/8: COPY setup.py setup.py
--> Using cache 91f4de717a059d1d2cf11a7c5a82b0df51f6d642932b1252a23ac930ee48fe20
--> 91f4de717a05
[1/2] STEP 7/8: COPY part2_solver.py part2_solver.py
--> Using cache c9d877c6f78ac1a6dc7888d66c62df728770fe2efb1ae5761554cb86af4ca8e1
--> c9d877c6f78a
[1/2] STEP 8/8: RUN :     && "${VENV}/bin/python3" setup.py install     && :
--> Using cache 029c0f49cfbf3db84fb924bad4ac2981e724603149eb4680a385d00e2b2edee1
--> 029c0f49cfbf
[2/2] STEP 1/8: FROM python:3.12-alpine AS runner
[2/2] STEP 2/8: ARG VENV="/opt/venv"
--> Using cache f4393dc8c9564f3c1a13471cc04c4eb6c4099e278f23a0e6eac7a9cf987941ad
--> f4393dc8c956
[2/2] STEP 3/8: COPY --from=base_image "${VENV}" "${VENV}"
--> 37d2f47a1951
[2/2] STEP 4/8: RUN addgroup -S appgroup && adduser -S appuser -G appgroup
--> eb6132fc6f04
[2/2] STEP 5/8: USER appuser
--> a527d2549b50
[2/2] STEP 6/8: ENV PATH="${VENV}/bin:${PATH}"
--> 84fd5450a968
[2/2] STEP 7/8: ENTRYPOINT [ "part2_solver.py" ]
--> c9f58b7ff881
[2/2] STEP 8/8: CMD [ "--help" ]
[2/2] COMMIT part-2-solver
--> e530f7835e36
Successfully tagged localhost/part-2-solver:latest
e530f7835e362b6f1de7615d0d9eae3e3fadbff3fa079f70b4b085b299d95eff
Part 2 solver

Usage:
    part2_solver.py <COORDS_TSV> <QUERIES_TSV>

Arguments:
    <COORDS_TSV>   Path to the TSV file containing coordinates.
    <QUERIES_TSV>  Path to the TSV file containing queries.

Options:
    -h --help  Show this screen.
make: Leaving directory '/home/hugo/projects/job_test/repo/test_2'
#+end_src

** Running
Let's run the code with the example and check if the results match.

#+BEGIN_SRC shell :results code :exports both
  cd ./test_2

  docker run --rm -i -v "${PWD}:${PWD}:ro" -w "${PWD}" \
         part-2-solver input_{1,2}.tsv
#+END_SRC

#+RESULTS:
#+begin_src shell
TR1	4	CHR1	7
TR1	13	CHR1	23
TR2	0	CHR2	10
TR2	10	CHR2	20
#+end_src

** Deleting the image
Run this command to delete the app image.

#+BEGIN_SRC shell :results code :exports both
  make -C ./test_2/ clean
#+END_SRC

#+RESULTS:
#+begin_src shell
make: Entering directory '/home/hugo/projects/job_test/repo/test_2'
docker image rm part-2-solver
Untagged: localhost/part-2-solver:latest
Deleted: 2ce10fd5308c098a52524c3fe238fc5ab912b9b12c8c7d291b939642c1d4b4d9
Deleted: f21063f9693c6b77125749c9a5f6a2be7f179c239e3a8dde4490d877353e2d5f
Deleted: e498e69f2cb7efbbe4500aac333093af137cd2f8e81e2f6c176d0b80e7bd17a3
Deleted: 78082a7940d34fa88112756a761e0b0968b63c1ee59e58c855d2b4310c0405c5
Deleted: 7e1c1ab4e840ae60a15a40f5bc5afd297ce95863fcbf6f9700536e8ba4cfae44
Deleted: fada75a70b086fd4eafd62df5c09f8640102ee8a4b39fced5e9b820b271cf04d
make: Leaving directory '/home/hugo/projects/job_test/repo/test_2'
#+end_src
